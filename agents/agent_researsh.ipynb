{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash Command Generation Agent System\n",
    "\n",
    "This notebook implements a multi-agent system to generate bash commands from natural language instructions. It uses a supervisor agent to manage two worker agents: a Generator and a Validator.\n",
    "\n",
    "![Agent System Diagram](./img/bash_agent_system.png)\n",
    "\n",
    "Let's start by setting up our environment and importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (0.2.15)\n",
      "Requirement already satisfied: langchain in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (0.2.15)\n",
      "Requirement already satisfied: langchain_openai in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (0.1.23)\n",
      "Requirement already satisfied: pydantic in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (2.8.2)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.27 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langgraph) (0.2.37)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langgraph) (1.0.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (0.1.108)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain_openai) (1.43.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from pydantic) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.10.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/lucasoliveira/miniconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph) (2.1)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph langchain langchain_openai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m load_dotenv()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Set up OpenAI API key\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<frozen os>:684\u001b[0m, in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:758\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "import operator\n",
    "import functools\n",
    "\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.tools import StructuredTool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Tools and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bash_command(task_description: str) -> str:\n",
    "    \"\"\"Generate a bash command based on the task description.\"\"\"\n",
    "    return f\"Generated bash command for: {task_description}\"\n",
    "\n",
    "def validate_bash_command(command: str) -> bool:\n",
    "    \"\"\"Validate the generated bash command.\"\"\"\n",
    "    # In a real scenario, you might want to implement actual validation logic\n",
    "    return True\n",
    "\n",
    "generate_tool = StructuredTool.from_function(\n",
    "    func=generate_bash_command,\n",
    "    name=\"generate_bash_command\",\n",
    "    description=\"Generate a bash command based on a task description\"\n",
    ")\n",
    "\n",
    "validate_tool = StructuredTool.from_function(\n",
    "    func=validate_bash_command,\n",
    "    name=\"validate_bash_command\",\n",
    "    description=\"Validate the generated bash command\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "generator_agent = create_openai_functions_agent(\n",
    "    llm,\n",
    "    [generate_tool],\n",
    "    \"You are an expert in generating bash commands from natural language instructions.\"\n",
    ")\n",
    "\n",
    "validator_agent = create_openai_functions_agent(\n",
    "    llm,\n",
    "    [validate_tool],\n",
    "    \"You are an expert in validating bash commands for correctness and safety.\"\n",
    ")\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "generator_node = functools.partial(agent_node, agent=generator_agent, name=\"Generator\")\n",
    "validator_node = functools.partial(agent_node, agent=validator_agent, name=\"Validator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"Generator\", \"Validator\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class RouteResponse(BaseModel):\n",
    "    next: Literal[tuple(options)]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.with_structured_output(RouteResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"Generator\", generator_node)\n",
    "workflow.add_node(\"Validator\", validator_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_task(task_description):\n",
    "    print(f\"Processing task: {task_description}\")\n",
    "    for s in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=task_description)]},\n",
    "        {\"recursion_limit\": 10},\n",
    "    ):\n",
    "        if \"__end__\" not in s:\n",
    "            print(s)\n",
    "            print(\"----\")\n",
    "    print(\"Task completed.\\n\")\n",
    "\n",
    "# Test with a few sample tasks\n",
    "sample_tasks = [\n",
    "    \"List all files in the current directory\",\n",
    "    \"Create a new directory named 'test_folder'\",\n",
    "    \"Count the number of lines in a file named 'example.txt'\"\n",
    "]\n",
    "\n",
    "for task in sample_tasks:\n",
    "    process_task(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Tasks from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_tasks_from_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        tasks = f.readlines()\n",
    "    \n",
    "    results = {}\n",
    "    for i, task in enumerate(tasks, 1):\n",
    "        task = task.strip()\n",
    "        print(f\"Processing task {i}/{len(tasks)}: {task}\")\n",
    "        \n",
    "        final_state = graph.invoke({\"messages\": [HumanMessage(content=task)]})\n",
    "        generated_command = final_state['messages'][-1].content\n",
    "        \n",
    "        results[str(i)] = json.dumps({\"invocation\": task, \"cmd\": generated_command})\n",
    "        \n",
    "    with open(\"data/new-nl2bash-data.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f\"Processed {len(tasks)} tasks. Results saved to 'data/new-nl2bash-data.json'\")\n",
    "\n",
    "# Process tasks from the file\n",
    "process_tasks_from_file(\"data/finetune.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
